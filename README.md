# Implementation-Of-Parallel-WebCrawler

Design and development of a Parallel Web Crawler which aimed to crawl over the web and map the various links and data from several web pages in order to index them over the database.
It is a backend process which help companies(owning search engines) to deliver quicker results to the people by enriching their data ware houses, hence indirectly helping the general public. It helped in optimizing the quality of the search results via the search engine, in the least possible time. There were several other challenges resolved during its development like eliminating redundancy etc. in order to have a quality product. 
This project was implemented in Java using MySQL. 
